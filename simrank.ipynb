{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename):\n",
    "    users = set()\n",
    "    user_directed_graph =  defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    ads = set()\n",
    "    ads_directed_graph = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    input = open(filename, 'r')\n",
    "    num_entries = int(input.readline())\n",
    "\n",
    "    for i in range(num_entries):\n",
    "        unformatted = input.readline()[:-1].split(',')\n",
    "        score = float(unformatted[-1])\n",
    "        unformatted.pop()\n",
    "        cur_user, cur_ad = [int(entry) for entry in unformatted]\n",
    "        users.add(cur_user)\n",
    "        user_directed_graph[cur_user][cur_ad] = score\n",
    "\n",
    "        ads.add(cur_ad)\n",
    "        ads_directed_graph[cur_ad][cur_user] = score\n",
    "\n",
    "    predict_user, predict_ad = [int(entry) for entry in input.readline().split(',')]\n",
    "    \n",
    "    return users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_simrank(users, user_directed_graph, ads, ads_directed_graph):\n",
    "    # note that this runs simrank with the partial sums memoization trick!\n",
    "    C1 = C2 = 0.8\n",
    "    similarity_user = defaultdict(lambda: defaultdict(float))\n",
    "    similarity_ads = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for u in users:\n",
    "        similarity_user[u][u] = 1.0\n",
    "    \n",
    "    for a in ads:\n",
    "        similarity_ads[a][a] = 1.0\n",
    "\n",
    "    partial_user = defaultdict(lambda: defaultdict(float))\n",
    "    partial_ads = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "\n",
    "    for iter in range(10):\n",
    "        for u in users:\n",
    "            for a in ads:\n",
    "                temp = 0.0\n",
    "                for u_ads in user_directed_graph[u]:\n",
    "                    temp += similarity_ads[u_ads][a]\n",
    "                partial_user[u][a] = temp\n",
    "        \n",
    "        list_users = list(users)\n",
    "        for i in range(len(list_users)):\n",
    "            for j in range(i + 1, len(list_users)):\n",
    "                temp = 0.0\n",
    "                u1, u2 = list_users[i], list_users[j]\n",
    "                for a in user_directed_graph[u2]:\n",
    "                    temp += partial_user[u1][a]\n",
    "                similarity_user[u1][u2] = similarity_user[u2][u1] =  C1 / (len(user_directed_graph[u1])*len(user_directed_graph[u2])) * temp\n",
    "    \n",
    "        for a in ads:\n",
    "            for u in users:\n",
    "                temp = 0.0\n",
    "                for a_user in ads_directed_graph[a]:\n",
    "                    temp += similarity_user[a_user][u]\n",
    "                partial_ads[a][u] = temp\n",
    "        \n",
    "        list_ads = list(ads)\n",
    "        for i in range(len(list_ads)):\n",
    "            for j in range(i+1, len(list_ads)):\n",
    "                temp = 0.0\n",
    "                a1, a2 = list_ads[i], list_ads[j]\n",
    "                for k in ads_directed_graph[a2]:\n",
    "                    temp += partial_ads[a1][k]\n",
    "                similarity_ads[a1][a2] = similarity_ads[a2][a1] = C2 / (len(ads_directed_graph[a1])*len(ads_directed_graph[a2])) * temp\n",
    "            \n",
    "    return similarity_user, similarity_ads\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_evidence(similarity_ads, ads_directed_graph, ads, similarity_users, user_directed_graph, users):\n",
    "    for _ in range(1):\n",
    "        copy_ads = list(ads)\n",
    "        for i in range(len(copy_ads)):\n",
    "            for j in range(i + 1, len(copy_ads)):\n",
    "                a1, a2 = copy_ads[i], copy_ads[j]\n",
    "                a1_neighbors, a2_neighbors = ads_directed_graph[a1].keys(), ads_directed_graph[a2].keys()\n",
    "\n",
    "                evidence_sum = 0.0\n",
    "                # starting adn ending 1 later to account for offset\n",
    "                for power in range(1, len(set(a1_neighbors).intersection(set(a2_neighbors))) + 1):\n",
    "                    evidence_sum += (1/2)**power\n",
    "                \n",
    "                similarity_ads[a1][a2] *= evidence_sum\n",
    "                similarity_ads[a2][a1] = similarity_ads[a1][a2]\n",
    "        \n",
    "        copy_users = list(users)\n",
    "        for i in range(len(copy_users)):\n",
    "            for j in range(i + 1, len(copy_users)):\n",
    "                u1, u2 = copy_users[i], copy_users[j]\n",
    "                if u1 == 1 and u2 == 4:\n",
    "                    print('hello')\n",
    "                u1_neighbors, u2_neighbors = user_directed_graph[u1].keys(), user_directed_graph[u2].keys()\n",
    "\n",
    "                evidence_sum = 0.0\n",
    "                # starting adn ending 1 later to account for offset\n",
    "                for power in range(1, len(set(u1_neighbors).intersection(set(u2_neighbors))) + 1):\n",
    "                    evidence_sum += (1/2)**power\n",
    "                \n",
    "                similarity_users[u1][u2] *= evidence_sum\n",
    "                similarity_users[u2][u1] = similarity_users[u1][u2]\n",
    "        \n",
    "    \n",
    "    return similarity_users, similarity_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_evidence(similarity_ads, ads_directed_graph, ads, similarity_users, user_directed_graph, users):\n",
    "    for _ in range(1):\n",
    "        copy_ads = list(ads)\n",
    "        for i in range(len(copy_ads)):\n",
    "            for j in range(i + 1, len(copy_ads)):\n",
    "                a1, a2 = copy_ads[i], copy_ads[j]\n",
    "                a1_neighbors, a2_neighbors = ads_directed_graph[a1].keys(), ads_directed_graph[a2].keys()\n",
    "\n",
    "                evidence_sum = 1-np.exp(-len(set(a1_neighbors).intersection(set(a2_neighbors))))\n",
    "                \n",
    "                similarity_ads[a1][a2] *= evidence_sum\n",
    "                similarity_ads[a2][a1] = similarity_ads[a1][a2]\n",
    "        \n",
    "        copy_users = list(users)\n",
    "        for i in range(len(copy_users)):\n",
    "            for j in range(i + 1, len(copy_users)):\n",
    "                u1, u2 = copy_users[i], copy_users[j]\n",
    "                u1_neighbors, u2_neighbors = user_directed_graph[u1].keys(), user_directed_graph[u2].keys()\n",
    "\n",
    "                evidence_sum = 1-np.exp(-len(set(u1_neighbors).intersection(set(u2_neighbors))))\n",
    "                # starting adn ending 1 later to account for offset\n",
    "                \n",
    "                similarity_users[u1][u2] *= evidence_sum\n",
    "                similarity_users[u2][u1] = similarity_users[u1][u2]\n",
    "    \n",
    "    \n",
    "    return similarity_users, similarity_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_top3(to_predict, similarity):\n",
    "    res = []\n",
    "    temp = similarity[to_predict].items()\n",
    "\n",
    "    value_key = {}\n",
    "    for k,v in temp:\n",
    "        if k != to_predict:\n",
    "            if v not in list(value_key.keys()):\n",
    "                value_key[v] = k\n",
    "                res.append((k,v))\n",
    "            else:\n",
    "                if k < value_key[v]:\n",
    "                    res.remove((value_key[v], v))\n",
    "                    value_key[v] = k\n",
    "                    res.append((k,v))\n",
    "                    \n",
    "    res = sorted(res, reverse=True, key= lambda x: (x[1], -x[0]))\n",
    "\n",
    "    return res[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutput(users, ads):\n",
    "    f = open(\"final_output.txt\", \"a\")\n",
    "    final_str = ''\n",
    "    for k,v in users:\n",
    "        final_str += f'{k},'\n",
    "    final_str = final_str[:-1]\n",
    "    final_str += '\\n'\n",
    "    f.write(final_str)\n",
    "\n",
    "    final_str = ''\n",
    "    for k,v in ads:\n",
    "        final_str += f'{k},'\n",
    "    final_str = final_str[:-1]\n",
    "    final_str += '\\n'\n",
    "    f.write(final_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad = read(filename='input_b.txt')\n",
    "similarity_user, similarity_ads = simple_simrank(users, user_directed_graph, ads, ads_directed_graph)\n",
    "\n",
    "top3_users = fetch_top3(predict_user, similarity_user)\n",
    "top3_ads = fetch_top3(predict_ad, similarity_ads)\n",
    "# top3_users, top3_ads\n",
    "writeOutput(top3_users, top3_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad = read(filename='input_b.txt')\n",
    "similarity_user, similarity_ads = simple_simrank(users, user_directed_graph, ads, ads_directed_graph)\n",
    "similarity_user, similarity_ads = geometric_evidence(similarity_ads, ads_directed_graph, ads, similarity_user, user_directed_graph, users)\n",
    "\n",
    "top3_users = fetch_top3(predict_user, similarity_user)\n",
    "top3_ads = fetch_top3(predict_ad, similarity_ads)\n",
    "# top3_users, top3_ads\n",
    "writeOutput(top3_users, top3_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad = read(filename='input_b.txt')\n",
    "similarity_user, similarity_ads = simple_simrank(users, user_directed_graph, ads, ads_directed_graph)\n",
    "similarity_user, similarity_ads = exponential_evidence(similarity_ads, ads_directed_graph, ads, similarity_user, user_directed_graph, users)\n",
    "\n",
    "top3_users = fetch_top3(predict_user, similarity_user)\n",
    "top3_ads = fetch_top3(predict_ad, similarity_ads)\n",
    "# top3_users, top3_ads\n",
    "writeOutput(top3_users, top3_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3_breaking_simrank(user_directed_graph, ads_directed_graph, users, ads):\n",
    "    dummy_ads = [10001, 10002, 10003]\n",
    "    # for d_ad in dummy_ads:\n",
    "    #     for u in users:\n",
    "    #         ads.add(d_ad)\n",
    "    #         temp = 0\n",
    "            \n",
    "    #         for neighbor in user_directed_graph[u]:\n",
    "    #             temp = max(temp, user_directed_graph[u][neighbor]) + 2\n",
    "    #         user_directed_graph[u][d_ad] = temp \n",
    "    #         ads_directed_graph[d_ad][u] = temp \n",
    "    # ads.add(10001)\n",
    "    # ads_directed_graph[10001][24481] = 6.0\n",
    "    # user_directed_graph[24481][10001] = 6.0\n",
    "    for d_ad in dummy_ads:\n",
    "        ads.add(d_ad)\n",
    "        for dup_ad in ads:\n",
    "            for associated_user in ads_directed_graph[dup_ad]:\n",
    "                ads_directed_graph[d_ad][associated_user] = ads_directed_graph[dup_ad][associated_user]\n",
    "                user_directed_graph[associated_user][d_ad] = user_directed_graph[associated_user][dup_ad]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {24481: 3.0, 579: 1.0, 76584: 2.0, 896: 3.0, 3374: 1.0, 661: 2.0, 5786: 1.0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(24481, 0.31884531578582276),\n",
       "  (76584, 0.26922201901093906),\n",
       "  (5786, 0.24932404233538857)],\n",
       " [(0, 0.5330713830366517), (5, 0.433789899997336), (37, 0.43378989999733597)])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad = read(filename='input_b.txt')\n",
    "# print(\"before: \" + str(ads_directed_graph[10001]))\n",
    "task3_breaking_simrank(user_directed_graph, ads_directed_graph, users, ads)\n",
    "# print(\"after: \" + str(ads_directed_graph[10001]))\n",
    "\n",
    "similarity_user, similarity_ads = simple_simrank(users, user_directed_graph, ads, ads_directed_graph)\n",
    "# similarity_user, similarity_ads = geometric_evidence(similarity_ads, ads_directed_graph, ads, similarity_user, user_directed_graph, users)\n",
    "\n",
    "top3_users = fetch_top3(predict_user, similarity_user)\n",
    "top3_ads = fetch_top3(predict_ad, similarity_ads)\n",
    "top3_users, top3_ads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {24481: 5.0})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads_directed_graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ads[6]\n",
    "# similarity_ads[10001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_Wqi(users, user_directed_graph, ads, ad_directed_graph):\n",
    "    user_spread = {}\n",
    "    for u in users:\n",
    "        weights = []\n",
    "        for k,v in user_directed_graph[u].items():\n",
    "            weights.append(v)\n",
    "        weights = np.array(weights)\n",
    "        user_spread[u] = np.exp(-weights.var())\n",
    "\n",
    "    ad_spread = {}\n",
    "    for a in ads:\n",
    "        weights = []\n",
    "        for k,v in ads_directed_graph[a].items():\n",
    "            weights.append(v)\n",
    "        weights = np.array(weights)\n",
    "        ad_spread[a] = np.exp(-weights.var())\n",
    "\n",
    "    # computing normalized weights\n",
    "    user_normalized_weights = defaultdict(lambda: defaultdict(float))\n",
    "    for u in users:\n",
    "        total_weight = 0.0\n",
    "        for neighbor in user_directed_graph[u]:\n",
    "            total_weight += user_directed_graph[u][neighbor]\n",
    "        \n",
    "        for neighbor in user_directed_graph[u]:\n",
    "            user_normalized_weights[u][neighbor] = user_directed_graph[u][neighbor] / total_weight\n",
    "    \n",
    "    ads_normalized_weights = defaultdict(lambda: defaultdict(float))\n",
    "    for a in ads:\n",
    "        total_weight = 0.0\n",
    "        for neighbor in ads_directed_graph[a]:\n",
    "            total_weight += ads_directed_graph[a][neighbor]\n",
    "        \n",
    "        for neighbor in ads_directed_graph[a]:\n",
    "            ads_normalized_weights[a][neighbor] = ads_directed_graph[u][neighbor] / total_weight\n",
    "    \n",
    "    w_user = defaultdict(lambda: defaultdict(float))\n",
    "    for q in users:\n",
    "        for i in user_directed_graph[u]:\n",
    "            w_user[q][i] = ad_spread[i] * user_normalized_weights[q][i]\n",
    "    \n",
    "    w_ads = defaultdict(lambda: defaultdict(float))\n",
    "    for q in ads:\n",
    "        for i in ads_directed_graph[q]:\n",
    "            w_ads[q][i] = user_spread[i] * ads_normalized_weights[q][i]\n",
    "    \n",
    "    return w_ads, w_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1091784693.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/gw/8z53b95100j5_2728fj_bzxh0000gn/T/ipykernel_57545/1091784693.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def simrank_plus_plus(user_directed_links, ad_directed_links, users, ads):\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def simrank_plus_plus(user_directed_graph, ad_directed_links, users, ads):\n",
    "    similarity_user = defaultdict(lambda: defaultdict(float))\n",
    "    similarity_ads = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    # computing spread\n",
    "    user_spread = {}\n",
    "    for u in users:\n",
    "        weights = []\n",
    "        for k,v in user_directed_graph[u].items():\n",
    "            weights.append(v)\n",
    "        weights = np.array(weights)\n",
    "        user_spread[u] = np.exp(-weights.var())\n",
    "\n",
    "    ad_spread = {}\n",
    "    for a in ads:\n",
    "        weights = []\n",
    "        for k,v in ads_directed_graph[a].items():\n",
    "            weights.append(v)\n",
    "        weights = np.array(weights)\n",
    "        ad_spread[a] = np.exp(-weights.var())\n",
    "\n",
    "    # computing normalized weights\n",
    "    user_normalized_weights = defaultdict(lambda: defaultdict(float))\n",
    "    for u in users:\n",
    "        total_weight = 0.0\n",
    "        for neighbor in user_directed_graph[u]:\n",
    "            total_weight += user_directed_graph[u][neighbor]\n",
    "        \n",
    "        for neighbor in user_directed_graph[u]:\n",
    "            user_normalized_weights[u][neighbor] = user_directed_graph[u][neighbor] / total_weight\n",
    "    \n",
    "    ads_normalized_weights = defaultdict(lambda: defaultdict(float))\n",
    "    for a in ads:\n",
    "        total_weight = 0.0\n",
    "        for neighbor in ads_directed_graph[a]:\n",
    "            total_weight += ads_directed_graph[a][neighbor]\n",
    "        \n",
    "        for neighbor in ads_directed_graph[a]:\n",
    "            ads_normalized_weights[a][neighbor] = ads_directed_graph[u][neighbor] / total_weight\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    return similarity_user, similarity_ads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ad_spread = {}\n",
    "user_spread = {}\n",
    "\n",
    "def spread_func(i, graph, ads):\n",
    "    if ads:\n",
    "        if i in list(ad_spread.keys()):\n",
    "            return ad_spread[i]\n",
    "        weights = []\n",
    "        for k,v in graph[i].items():\n",
    "            weights.append(v)\n",
    "        weights = np.array(weights)\n",
    "        ad_spread[i] = np.exp(-weights.var())\n",
    "        return ad_spread[i]\n",
    "    else:\n",
    "        if i in list(user_spread.keys()):\n",
    "            return user_spread[i]\n",
    "        weights = []\n",
    "        for k,v in graph[i].items():\n",
    "            weights.append(v)\n",
    "        weights = np.array(weights)\n",
    "        user_spread[i] = np.exp(-weights.var())\n",
    "        return user_spread[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
