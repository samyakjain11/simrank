{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename):\n",
    "    users = set()\n",
    "    user_directed_graph =  defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    ads = set()\n",
    "    ads_directed_graph = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    input = open(filename, 'r')\n",
    "    num_entries = int(input.readline())\n",
    "\n",
    "    for i in range(num_entries):\n",
    "        unformatted = input.readline()[:-1].split(',')\n",
    "        score = float(unformatted[-1])\n",
    "        unformatted.pop()\n",
    "        cur_user, cur_ad = [int(entry) for entry in unformatted]\n",
    "        users.add(cur_user)\n",
    "        user_directed_graph[cur_user][cur_ad] = score\n",
    "\n",
    "        ads.add(cur_ad)\n",
    "        ads_directed_graph[cur_ad][cur_user] = score\n",
    "\n",
    "    predict_user, predict_ad = [int(entry) for entry in input.readline().split(',')]\n",
    "    \n",
    "    return users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad = read(filename='sample_input.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_simrank(users, user_directed_graph, ads, ads_directed_graph):\n",
    "    # note that this runs simrank with the partial sums memoization trick!\n",
    "    C1 = C2 = 0.8\n",
    "    similarity_user = defaultdict(lambda: defaultdict(float))\n",
    "    similarity_ads = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for u in users:\n",
    "        similarity_user[u][u] = 1.0\n",
    "    \n",
    "    for a in ads:\n",
    "        similarity_ads[a][a] = 1.0\n",
    "\n",
    "    partial_user = defaultdict(lambda: defaultdict(float))\n",
    "    partial_ads = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for iter in range(10):\n",
    "        for u in users:\n",
    "            for a in ads:\n",
    "                temp = 0.0\n",
    "                for u_ads in user_directed_graph[u]:\n",
    "                    temp += similarity_ads[u_ads][a]\n",
    "                partial_user[u][a] = temp\n",
    "        \n",
    "        list_users = list(users)\n",
    "        for i in range(len(list_users)):\n",
    "            for j in range(i + 1, len(list_users)):\n",
    "                temp = 0.0\n",
    "                u1, u2 = list_users[i], list_users[j]\n",
    "                for a in user_directed_graph[u2]:\n",
    "                    temp += partial_user[u1][a]\n",
    "                similarity_user[u1][u2] = similarity_user[u2][u1] =  C1 / (len(user_directed_graph[u1])*len(user_directed_graph[u2])) * temp\n",
    "    \n",
    "        for a in ads:\n",
    "            for u in users:\n",
    "                temp = 0.0\n",
    "                for a_user in ads_directed_graph[a]:\n",
    "                    temp += similarity_user[a_user][u]\n",
    "                partial_ads[a][u] = temp\n",
    "        \n",
    "        list_ads = list(ads)\n",
    "        for i in range(len(list_ads)):\n",
    "            for j in range(i+1, len(list_ads)):\n",
    "                temp = 0.0\n",
    "                a1, a2 = list_ads[i], list_ads[j]\n",
    "                for k in ads_directed_graph[a2]:\n",
    "                    temp += partial_ads[a1][k]\n",
    "                similarity_ads[a1][a2] = similarity_ads[a2][a1] = C2 / (len(ads_directed_graph[a1])*len(ads_directed_graph[a2])) * temp\n",
    "            \n",
    "    return similarity_user, similarity_ads\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_top3(to_predict, similarity):\n",
    "    res = []\n",
    "    temp = similarity[to_predict].items()\n",
    "    return temp\n",
    "    # for k,v in temp:\n",
    "    #     if k != to_predict:\n",
    "    #         res.append((k,v))\n",
    "    # res = sorted(res, reverse=True, key= lambda x: (x[1], -x[0]))\n",
    "    # return res[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_items([(1, 1.0), (2, 0.6186308753930624), (3, 0.6186308753930624), (4, 0.4372617507861247), (5, 0.0)]),\n",
       " dict_items([(20, 1.0), (1235, 0.0), (38, 0.5465819558350666), (8271, 0.0)]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users, user_directed_graph, ads, ads_directed_graph, predict_user, predict_ad = read(filename='sample_input.txt')\n",
    "# similarity_user, similarity_ads = simrank(users, ads, user_directed_graph, ads_directed_graph, 10, 0.8, 0.8)\n",
    "similarity_user, similarity_ads = simple_simrank(users, user_directed_graph, ads, ads_directed_graph)\n",
    "top3_users = fetch_top3(predict_user, similarity_user)\n",
    "top3_ads = fetch_top3(predict_ad, similarity_ads)\n",
    "top3_users, top3_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
